{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOgSWOPlvsB55fjgHqDLrqw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4GG5auxRKcuk"},"source":["# GOOGLE COLAB"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"km0c6bTSgEC8","executionInfo":{"status":"ok","timestamp":1625421184856,"user_tz":-180,"elapsed":267,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}},"outputId":"326d24fe-c8df-4313-f73e-0eec7768277b"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d0K7eBFfgFZj","executionInfo":{"status":"ok","timestamp":1625428778091,"user_tz":-180,"elapsed":264,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["import os\n","os.chdir('/gdrive/My Drive/Huawei')"],"execution_count":157,"outputs":[]},{"cell_type":"code","metadata":{"id":"IVYz1Hn8d4rs","executionInfo":{"status":"ok","timestamp":1625428779112,"user_tz":-180,"elapsed":2,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["import pandas as pd\n","from sklearn.preprocessing import MultiLabelBinarizer\n","import numpy as np\n","import datetime"],"execution_count":158,"outputs":[]},{"cell_type":"code","metadata":{"id":"vzFGWxgvd6VX","executionInfo":{"status":"ok","timestamp":1625423898668,"user_tz":-180,"elapsed":267,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["root = '/gdrive/My Drive/Huawei/'\n","veriler1 = pd.read_csv('film_data.csv')\n","veriler2 = pd.read_csv('out.csv')\n"],"execution_count":64,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KA-gwHRoKg6H"},"source":["NLP de işlenen descriptionları içeren csv dosyası ile ana csv dosyası birleştirildi."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fi_utB7Pef8w","executionInfo":{"status":"ok","timestamp":1625426559977,"user_tz":-180,"elapsed":267,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}},"outputId":"81a4daa4-e25a-4f78-fbb3-f851b3f5baf6"},"source":["veriler = pd.concat([veriler1, veriler2], axis=1)\n","print(veriler.columns)"],"execution_count":148,"outputs":[{"output_type":"stream","text":["Index(['Unnamed: 0', 'date_published', 'genre', 'duration', 'country',\n","       'language', 'description', 'avg_vote', 'votes', '0'],\n","      dtype='object')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_Z8TXa4rKsIv"},"source":["#VERİ ÖNİŞLEME FONKSİYONLARI "]},{"cell_type":"markdown","metadata":{"id":"XDGmjoOBK30H"},"source":["tüm özelliklerin işlendiği yer IMDB_Rate.ipynb dosyasıdır. Elenen veriler ve karşılaştırmalar oradadır."]},{"cell_type":"code","metadata":{"id":"gw0IKUMPt8-Y","executionInfo":{"status":"ok","timestamp":1625426560800,"user_tz":-180,"elapsed":6,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["def datetime_func(veri):\n","  x = datetime.datetime.now()\n","  date = veri\n","  date_list = []\n","  for i in date:\n","      y = i.split(\"-\")\n","      calculate_year = (x.year - int(y[0])) * 365\n","      calculate_month = (x.month - int(y[1])) * 30\n","      calculate_day = x.day - int(y[2])\n","      new_date = calculate_year + calculate_month + calculate_day\n","      date_list.append(new_date)\n","\n","  date_df = pd.DataFrame(date_list)\n","  from sklearn.preprocessing import StandardScaler\n","  sc = StandardScaler()\n","  date_df_new = sc.fit_transform(date_df)\n","  date_df_new = pd.DataFrame(date_df_new, columns=[\"date_release\"], index=veriler.index)\n","  return date_df_new"],"execution_count":149,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZIkna-quxUK","executionInfo":{"status":"ok","timestamp":1625426561814,"user_tz":-180,"elapsed":6,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["def description_func(veri):\n","  from sklearn import preprocessing\n","  description = veri\n","\n","  ohe = preprocessing.OneHotEncoder()\n","  description = ohe.fit_transform(description).toarray()\n","  return description"],"execution_count":150,"outputs":[]},{"cell_type":"code","metadata":{"id":"49E7q66qvH7V","executionInfo":{"status":"ok","timestamp":1625426562972,"user_tz":-180,"elapsed":1,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["def votes_func(veri):\n","  from sklearn.preprocessing import StandardScaler\n","  sc = StandardScaler()\n","\n","  votes = sc.fit_transform(veri)\n","  votes = pd.DataFrame(votes, columns=[\"votes\"], index=veriler.index)\n","  return votes"],"execution_count":151,"outputs":[]},{"cell_type":"code","metadata":{"id":"gspGszxAvdyo","executionInfo":{"status":"ok","timestamp":1625426563660,"user_tz":-180,"elapsed":2,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["def genre_func(veri):\n","  veriler = pd.DataFrame(veri)\n","  veriler[\"genre\"] = veriler[\"genre\"].str.replace(\" \", \"\")\n","  veriler[\"genre\"] = veriler[\"genre\"].str.split(\",\")\n","  \n","  mlb = MultiLabelBinarizer()\n","  genre = veriler['genre']\n","\n","  encoded = pd.DataFrame(mlb.fit_transform(genre), columns=mlb.classes_, index=veriler.index)\n","\n","  return encoded"],"execution_count":152,"outputs":[]},{"cell_type":"code","metadata":{"id":"JYjnRDLmv1iK","executionInfo":{"status":"ok","timestamp":1625426564632,"user_tz":-180,"elapsed":2,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["def veri_birlestirme_func(encoded, votes):\n","  feature1 = pd.DataFrame(data=encoded)\n","  feature4 = pd.DataFrame(data=votes)\n","  feature5 = pd.DataFrame(data=duration)\n","  feature6 = pd.DataFrame(data=date_df_new)\n","  feature7 = pd.DataFrame(data=description)\n","\n","\n","  features_new = pd.concat([feature1, feature4], axis=1)\n","  features_new = pd.concat([features_new, feature5], axis=1)\n","  features_new = pd.concat([features_new, feature6], axis=1)\n","  features_new = pd.concat([features_new, feature7], axis=1)\n","  return features_new\n"],"execution_count":153,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gxQqqLntLKiQ"},"source":["# PREDİCT FONKSİYONU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k6T1a9GpeLcG","executionInfo":{"status":"ok","timestamp":1625426565744,"user_tz":-180,"elapsed":256,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}},"outputId":"79812fd2-4304-4133-c6ed-badb9a630cb8"},"source":["import pickle\n","model = pickle.load(open(\"model.kayit\",\"rb\"))\n","def predict(veriler):\n","  date_df_new = datetime_func(veriler[\"date_published\"])\n","  description = description_func(veriler[\"0\"].to_frame())\n","  duration = veriler[\"duration\"]\n","  votes = votes_func(veriler[[\"votes\"]])\n","  encoded= genre_func(veriler[\"genre\"])\n","  features_new = veri_birlestirme_func(encoded, votes)\n","  output = model.predict(features_new.values)\n","  output_df = pd.DataFrame(output, columns=[\"predicted_rating\"], index=veriler.index)\n","  print(output_df)\n","  #output_df.to_csv(\"output.csv\")"],"execution_count":154,"outputs":[{"output_type":"stream","text":["[19:22:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQi56hFfwZUf","executionInfo":{"status":"ok","timestamp":1625426569749,"user_tz":-180,"elapsed":1918,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}},"outputId":"410e3cef-6003-40bd-9bf0-658476187731"},"source":["predict(veriler)\n"],"execution_count":155,"outputs":[{"output_type":"stream","text":["       predicted_rating\n","0              7.419049\n","1              5.117787\n","2              6.660292\n","3              4.684600\n","4              6.333872\n","...                 ...\n","70685          5.070696\n","70686          6.894261\n","70687          6.028717\n","70688          5.554717\n","70689          7.250593\n","\n","[70690 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uAnjidWsDtrf"},"source":["# FARKLI VERİ SETİ GİRİŞİ İÇİN BURAYI KULLANINIZ."]},{"cell_type":"code","metadata":{"id":"nDf-r_hPDy86","executionInfo":{"status":"ok","timestamp":1625428788763,"user_tz":-180,"elapsed":309,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["yeni_veri = pd.read_csv('film_data.csv')"],"execution_count":159,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o14iKMdZ62Uq","executionInfo":{"status":"ok","timestamp":1625428790166,"user_tz":-180,"elapsed":432,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}},"outputId":"7700a291-9b3b-4933-b317-a16871e2bb06"},"source":["import gensim\n","import numpy as np\n","import pandas as pd\n","import re\n","import string\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import gensim\n"],"execution_count":160,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a7vkywMiLZtr"},"source":["# VERİ ÖNİŞLEME"]},{"cell_type":"markdown","metadata":{"id":"YWG71QI7LdiB"},"source":["Karşılaştırmalar ve Veri önişlemelerinin tamamı NLP.ipynb ve IMDB_Rate.ipynb dosyalarında bulunmaktadır."]},{"cell_type":"code","metadata":{"id":"yHX-OviJ-tgh","executionInfo":{"status":"ok","timestamp":1625428955718,"user_tz":-180,"elapsed":7,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["def veri_okunmasi(data):\n","  description2 = data[\"description\"]\n","  nok_isaretleri_kümesi = string.punctuation\n","  etkisiz_kelimeler_kümesi = [\"year\",\"film\",\"0o\", \"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"able\", \"about\", \"above\", \"abst\", \"ac\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"ad\", \"added\", \"adj\", \"ae\", \"af\", \"affected\", \"affecting\", \"affects\", \"after\", \"afterwards\", \"ag\", \"again\", \"against\", \"ah\", \"ain\", \"ain't\", \"aj\", \"al\", \"all\", \"allow\", \"allows\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"ao\", \"ap\", \"apart\", \"apparently\", \"appear\", \"appreciate\", \"appropriate\", \"approximately\", \"ar\", \"are\", \"aren\", \"arent\", \"aren't\", \"arise\", \"around\", \"as\", \"a's\", \"aside\", \"ask\", \"asking\", \"associated\", \"at\", \"au\", \"auth\", \"av\", \"available\", \"aw\", \"away\", \"awfully\", \"ax\", \"ay\", \"az\", \"b\", \"b1\", \"b2\", \"b3\", \"ba\", \"back\", \"bc\", \"bd\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"begin\", \"beginning\", \"beginnings\", \"begins\", \"behind\", \"being\", \"believe\", \"below\", \"beside\", \"besides\", \"best\", \"better\", \"between\", \"beyond\", \"bi\", \"bill\", \"biol\", \"bj\", \"bk\", \"bl\", \"bn\", \"both\", \"bottom\", \"bp\", \"br\", \"brief\", \"briefly\", \"bs\", \"bt\", \"bu\", \"but\", \"bx\", \"by\", \"c\", \"c1\", \"c2\", \"c3\", \"ca\", \"call\", \"came\", \"can\", \"cannot\", \"cant\", \"can't\", \"cause\", \"causes\", \"cc\", \"cd\", \"ce\", \"certain\", \"certainly\", \"cf\", \"cg\", \"ch\", \"changes\", \"ci\", \"cit\", \"cj\", \"cl\", \"clearly\", \"cm\", \"c'mon\", \"cn\", \"co\", \"com\", \"come\", \"comes\", \"con\", \"concerning\", \"consequently\", \"consider\", \"considering\", \"contain\", \"containing\", \"contains\", \"corresponding\", \"could\", \"couldn\", \"couldnt\", \"couldn't\", \"course\", \"cp\", \"cq\", \"cr\", \"cry\", \"cs\", \"c's\", \"ct\", \"cu\", \"currently\", \"cv\", \"cx\", \"cy\", \"cz\", \"d\", \"d2\", \"da\", \"date\", \"dc\", \"dd\", \"de\", \"definitely\", \"describe\", \"described\", \"despite\", \"detail\", \"df\", \"di\", \"did\", \"didn\", \"didn't\", \"different\", \"dj\", \"dk\", \"dl\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doing\", \"don\", \"done\", \"don't\", \"down\", \"downwards\", \"dp\", \"dr\", \"ds\", \"dt\", \"du\", \"due\", \"during\", \"dx\", \"dy\", \"e\", \"e2\", \"e3\", \"ea\", \"each\", \"ec\", \"ed\", \"edu\", \"ee\", \"ef\", \"effect\", \"eg\", \"ei\", \"eight\", \"eighty\", \"either\", \"ej\", \"el\", \"eleven\", \"else\", \"elsewhere\", \"em\", \"empty\", \"en\", \"end\", \"ending\", \"enough\", \"entirely\", \"eo\", \"ep\", \"eq\", \"er\", \"es\", \"especially\", \"est\", \"et\", \"et-al\", \"etc\", \"eu\", \"ev\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\", \"example\", \"except\", \"ey\", \"f\", \"f2\", \"fa\", \"far\", \"fc\", \"few\", \"ff\", \"fi\", \"fifteen\", \"fifth\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"fix\", \"fj\", \"fl\", \"fn\", \"fo\", \"followed\", \"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \"forty\", \"found\", \"four\", \"fr\", \"from\", \"front\", \"fs\", \"ft\", \"fu\", \"full\", \"further\", \"furthermore\", \"fy\", \"g\", \"ga\", \"gave\", \"ge\", \"get\", \"gets\", \"getting\", \"gi\", \"give\", \"given\", \"gives\", \"giving\", \"gj\", \"gl\", \"go\", \"goes\", \"going\", \"gone\", \"got\", \"gotten\", \"gr\", \"greetings\", \"gs\", \"gy\", \"h\", \"h2\", \"h3\", \"had\", \"hadn\", \"hadn't\", \"happens\", \"hardly\", \"has\", \"hasn\", \"hasnt\", \"hasn't\", \"have\", \"haven\", \"haven't\", \"having\", \"he\", \"hed\", \"he'd\", \"he'll\", \"hello\", \"help\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"here's\", \"hereupon\", \"hers\", \"herself\", \"hes\", \"he's\", \"hh\", \"hi\", \"hid\", \"him\", \"himself\", \"his\", \"hither\", \"hj\", \"ho\", \"home\", \"hopefully\", \"how\", \"howbeit\", \"however\", \"how's\", \"hr\", \"hs\", \"http\", \"hu\", \"hundred\", \"hy\", \"i\", \"i2\", \"i3\", \"i4\", \"i6\", \"i7\", \"i8\", \"ia\", \"ib\", \"ibid\", \"ic\", \"id\", \"i'd\", \"ie\", \"if\", \"ig\", \"ignored\", \"ih\", \"ii\", \"ij\", \"il\", \"i'll\", \"im\", \"i'm\", \"immediate\", \"immediately\", \"importance\", \"important\", \"in\", \"inasmuch\", \"inc\", \"indeed\", \"index\", \"indicate\", \"indicated\", \"indicates\", \"information\", \"inner\", \"insofar\", \"instead\", \"interest\", \"into\", \"invention\", \"inward\", \"io\", \"ip\", \"iq\", \"ir\", \"is\", \"isn\", \"isn't\", \"it\", \"itd\", \"it'd\", \"it'll\", \"its\", \"it's\", \"itself\", \"iv\", \"i've\", \"ix\", \"iy\", \"iz\", \"j\", \"jj\", \"jr\", \"js\", \"jt\", \"ju\", \"just\", \"k\", \"ke\", \"keep\", \"keeps\", \"kept\", \"kg\", \"kj\", \"km\", \"know\", \"known\", \"knows\", \"ko\", \"l\", \"l2\", \"la\", \"largely\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"lb\", \"lc\", \"le\", \"least\", \"les\", \"less\", \"lest\", \"let\", \"lets\", \"let's\", \"lf\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"lj\", \"ll\", \"ll\", \"ln\", \"lo\", \"look\", \"looking\", \"looks\", \"los\", \"lr\", \"ls\", \"lt\", \"ltd\", \"m\", \"m2\", \"ma\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\", \"maybe\", \"me\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\", \"mightn\", \"mightn't\", \"mill\", \"million\", \"mine\", \"miss\", \"ml\", \"mn\", \"mo\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"mr\", \"mrs\", \"ms\", \"mt\", \"mu\", \"much\", \"mug\", \"must\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"n\", \"n2\", \"na\", \"name\", \"namely\", \"nay\", \"nc\", \"nd\", \"ne\", \"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needn\", \"needn't\", \"needs\", \"neither\", \"never\", \"nevertheless\", \"new\", \"next\", \"ng\", \"ni\", \"nine\", \"ninety\", \"nj\", \"nl\", \"nn\", \"no\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"nor\", \"normally\", \"nos\", \"not\", \"noted\", \"nothing\", \"novel\", \"now\", \"nowhere\", \"nr\", \"ns\", \"nt\", \"ny\", \"o\", \"oa\", \"ob\", \"obtain\", \"obtained\", \"obviously\", \"oc\", \"od\", \"of\", \"off\", \"often\", \"og\", \"oh\", \"oi\", \"oj\", \"ok\", \"okay\", \"ol\", \"old\", \"om\", \"omitted\", \"on\", \"once\", \"one\", \"ones\", \"only\", \"onto\", \"oo\", \"op\", \"oq\", \"or\", \"ord\", \"os\", \"ot\", \"other\", \"others\", \"otherwise\", \"ou\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"ow\", \"owing\", \"own\", \"ox\", \"oz\", \"p\", \"p1\", \"p2\", \"p3\", \"page\", \"pagecount\", \"pages\", \"par\", \"part\", \"particular\", \"particularly\", \"pas\", \"past\", \"pc\", \"pd\", \"pe\", \"per\", \"perhaps\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"placed\", \"please\", \"plus\", \"pm\", \"pn\", \"po\", \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"pq\", \"pr\", \"predominantly\", \"present\", \"presumably\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\", \"provides\", \"ps\", \"pt\", \"pu\", \"put\", \"py\", \"q\", \"qj\", \"qu\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"r2\", \"ra\", \"ran\", \"rather\", \"rc\", \"rd\", \"re\", \"readily\", \"really\", \"reasonably\", \"recent\", \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\", \"research-articl\", \"respectively\", \"resulted\", \"resulting\", \"results\", \"rf\", \"rh\", \"ri\", \"right\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\", \"rs\", \"rt\", \"ru\", \"run\", \"rv\", \"ry\", \"s\", \"s2\", \"sa\", \"said\", \"same\", \"saw\", \"say\", \"saying\", \"says\", \"sc\", \"sd\", \"se\", \"sec\", \"second\", \"secondly\", \"section\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sensible\", \"sent\", \"serious\", \"seriously\", \"seven\", \"several\", \"sf\", \"shall\", \"shan\", \"shan't\", \"she\", \"shed\", \"she'd\", \"she'll\", \"shes\", \"she's\", \"should\", \"shouldn\", \"shouldn't\", \"should've\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \"si\", \"side\", \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \"sincere\", \"six\", \"sixty\", \"sj\", \"sl\", \"slightly\", \"sm\", \"sn\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\", \"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"sp\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"sq\", \"sr\", \"ss\", \"st\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\", \"sy\", \"system\", \"sz\", \"t\", \"t1\", \"t2\", \"t3\", \"take\", \"taken\", \"taking\", \"tb\", \"tc\", \"td\", \"te\", \"tell\", \"ten\", \"tends\", \"tf\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"that'll\", \"thats\", \"that's\", \"that've\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \"there'll\", \"thereof\", \"therere\", \"theres\", \"there's\", \"thereto\", \"thereupon\", \"there've\", \"these\", \"they\", \"theyd\", \"they'd\", \"they'll\", \"theyre\", \"they're\", \"they've\", \"thickv\", \"thin\", \"think\", \"third\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"three\", \"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"ti\", \"til\", \"tip\", \"tj\", \"tl\", \"tm\", \"tn\", \"to\", \"together\", \"too\", \"took\", \"top\", \"toward\", \"towards\", \"tp\", \"tq\", \"tr\", \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"t's\", \"tt\", \"tv\", \"twelve\", \"twenty\", \"twice\", \"two\", \"tx\", \"u\", \"u201d\", \"ue\", \"ui\", \"uj\", \"uk\", \"um\", \"un\", \"under\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \"unto\", \"uo\", \"up\", \"upon\", \"ups\", \"ur\", \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\", \"ut\", \"v\", \"va\", \"value\", \"various\", \"vd\", \"ve\", \"ve\", \"very\", \"via\", \"viz\", \"vj\", \"vo\", \"vol\", \"vols\", \"volumtype\", \"vq\", \"vs\", \"vt\", \"vu\", \"w\", \"wa\", \"want\", \"wants\", \"was\", \"wasn\", \"wasnt\", \"wasn't\", \"way\", \"we\", \"wed\", \"we'd\", \"welcome\", \"well\", \"we'll\", \"well-b\", \"went\", \"were\", \"we're\", \"weren\", \"werent\", \"weren't\", \"we've\", \"what\", \"whatever\", \"what'll\", \"whats\", \"what's\", \"when\", \"whence\", \"whenever\", \"when's\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"where's\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \"whod\", \"whoever\", \"whole\", \"who'll\", \"whom\", \"whomever\", \"whos\", \"who's\", \"whose\", \"why\", \"why's\", \"wi\", \"widely\", \"will\", \"willing\", \"wish\", \"with\", \"within\", \"without\", \"wo\", \"won\", \"wonder\", \"wont\", \"won't\", \"words\", \"world\", \"would\", \"wouldn\", \"wouldnt\", \"wouldn't\", \"www\", \"x\", \"x1\", \"x2\", \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\", \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y\", \"y2\", \"yes\", \"yet\", \"yj\", \"yl\", \"you\", \"youd\", \"you'd\", \"you'll\", \"your\", \"youre\", \"you're\", \"yours\", \"yourself\", \"yourselves\", \"you've\", \"yr\", \"ys\", \"yt\", \"z\", \"zero\", \"zi\", \"zz\"]\n","  return description2, nok_isaretleri_kümesi, etkisiz_kelimeler_kümesi"],"execution_count":172,"outputs":[]},{"cell_type":"code","metadata":{"id":"G-kbIWAY-90J","executionInfo":{"status":"ok","timestamp":1625428954429,"user_tz":-180,"elapsed":438,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["def veri_temizleme(metin, nok_isaretleri_kümesi, etkisiz_kelimeler_kümesi):\n","    metin = metin.lower()\n","    metin = metin.replace(\"\\\\n\", \" \")# Verisetimizdeki yeni satır karekterleri, boşluk karekteriyle değiştirdik.\n","    # Kesme işareti ve sonrasındaki karekterlerin kaldırılması\n","    metin = re.sub(\"’(\\w+)\", \"\", metin)\n","    metin = re.sub(\"'(\\w+)\", \"\", metin)\n","    metin = re.sub(\"[“,‘,’,”]\", \"\", metin)\n","    # Sayıların Kaldırılması\n","    metin = re.sub(\"[0-9]+\", \"\", metin)\n","    # Noktalama işaretlerinin kaldırılması\n","    metin = \"\".join(list(map(lambda x: x if x not in nok_isaretleri_kümesi else \" \", metin)))\n","    # Etkisiz kelimelerin bir kısmının kaldırılması\n","    metin = \" \".join([i for i in metin.split() if i not in etkisiz_kelimeler_kümesi])\n","    # Metinde tek kalan harfleri de çıkartalım\n","    metin = \" \".join([i for i in metin.split() if len(i) > 1])\n","\n","    return metin"],"execution_count":171,"outputs":[]},{"cell_type":"code","metadata":{"id":"CpA2jP4q_CqA","executionInfo":{"status":"ok","timestamp":1625428805655,"user_tz":-180,"elapsed":275,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["def lemma_func(temiz_data):\n","  from nltk.stem import WordNetLemmatizer\n","  nltk.download('punkt')\n","  nltk.download('wordnet')\n","  lemmatizer = WordNetLemmatizer()\n","  lemmatized_data=[]\n","  for i in temiz_data:\n","    word_list = nltk.word_tokenize(i)\n","    lemmatized_data.append(' '.join([lemmatizer.lemmatize(w) for w in word_list]))\n","  lemmatized_data = pd.Series(lemmatized_data)\n","  return lemmatized_data"],"execution_count":164,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hxoO5_joLyOl"},"source":["# Daha önce eğitilmiş modelin kullanımı"]},{"cell_type":"code","metadata":{"id":"e1rk2XW2_W1i","executionInfo":{"status":"ok","timestamp":1625428807829,"user_tz":-180,"elapsed":261,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["def lda_func(temiz_data, tokenized_data, kelime_listesi):\n","  lda_model = gensim.models.ldamodel.LdaModel.load('lda_train.model3')\n","  class_names = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"]\n","  son_sonuc = []\n","  for j in range(len(temiz_data)):\n","    bow = kelime_listesi.doc2bow(tokenized_data[j])\n","    results = lda_model.get_document_topics(bow, minimum_probability= 0.0, per_word_topics=False)\n","    sonuc = []\n","    for i in range(9):\n","      sonuc.append(results[i][1])\n","    son_sonuc.append(class_names[np.argmax([sonuc])])\n","  return son_sonuc"],"execution_count":165,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9eC9KTwKL4Ix"},"source":["# Yeni veri setleri için PREDİCT fonksiyonu"]},{"cell_type":"code","metadata":{"id":"rFCE7u3g6XsU","executionInfo":{"status":"ok","timestamp":1625428958739,"user_tz":-180,"elapsed":272,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}}},"source":["def predict_new(veriler):\n","  description2, nok_isaretleri_kümesi, etkisiz_kelimeler_kümesi = veri_okunmasi(veriler)\n","  temiz_data = description2.apply(lambda x:veri_temizleme(x, nok_isaretleri_kümesi, etkisiz_kelimeler_kümesi))\n","  lemmatized_data = lemma_func(temiz_data)\n","  tokenized_data = lemmatized_data.apply(lambda x: x.split())\n","  kelime_listesi = gensim.corpora.Dictionary(tokenized_data)\n","  dokuman_terim_matrisi = [kelime_listesi.doc2bow(terim) for terim in tokenized_data]\n","  son_sonuc = lda_func(temiz_data, tokenized_data, kelime_listesi)\n","  son_sonuc = pd.DataFrame(son_sonuc)\n","\n","  date_df_new = datetime_func(veriler[\"date_published\"])\n","  description = description_func(son_sonuc)\n","  duration = veriler[\"duration\"]\n","  votes = votes_func(veriler[[\"votes\"]])\n","  encoded= genre_func(veriler[\"genre\"])\n","  features_new = veri_birlestirme_func(encoded, votes)\n","  output = model.predict(features_new.values)\n","  output_df = pd.DataFrame(output, columns=[\"predicted_rating\"], index=veriler.index)\n","  print(output_df)"],"execution_count":173,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEOm91K96Tnl","executionInfo":{"status":"ok","timestamp":1625429021328,"user_tz":-180,"elapsed":61143,"user":{"displayName":"Berkay Yıldırım","photoUrl":"","userId":"05758311791842332076"}},"outputId":"a65b2c89-a387-4d1c-8777-7693f38c1094"},"source":["predict_new(yeni_veri)"],"execution_count":174,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","       predicted_rating\n","0              7.419049\n","1              5.117787\n","2              6.660292\n","3              4.684600\n","4              6.333872\n","...                 ...\n","70685          5.070696\n","70686          6.894261\n","70687          6.028717\n","70688          5.554717\n","70689          7.250593\n","\n","[70690 rows x 1 columns]\n"],"name":"stdout"}]}]}